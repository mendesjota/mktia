"""Streamlit app para analisar fachadas de bares Brahma.

Este aplicativo permite enviar imagens, PDFs ou arquivos PPTX e realizar uma
analise preliminar usando as APIs da OpenAI ou Gemini. O objetivo e servir
como ponto de partida para treinar um modelo mais robusto.
"""

from io import BytesIO
from pathlib import Path
import base64

import streamlit as st
from pptx import Presentation
from PIL import Image, UnidentifiedImageError
import PyPDF2
import openai
import google.generativeai as genai
from google.api_core import exceptions # Importa exce√ß√µes da API do Google

# --- Configura√ß√µes da P√°gina Streamlit ---
st.set_page_config(
    page_title="Or√°culo de Fachadas Brahma",
    page_icon="üç∫",
    layout="centered",
    initial_sidebar_state="expanded"
)

# --- Fun√ß√µes de An√°lise com APIs ---

def call_openai_api(prompt: str, api_key: str, image: Image.Image = None) -> str:
    """
    Envia o prompt (e opcionalmente uma imagem) para a API da OpenAI e retorna a resposta.
    Utiliza modelos de vis√£o se uma imagem for fornecida.
    """
    if not api_key:
        return "Erro: Chave da API OpenAI n√£o fornecida."

    openai.api_key = api_key
    messages_payload = []
    
    # Adiciona o texto do prompt como parte do conte√∫do
    content_list = [{"type": "text", "text": prompt}]

    # Se uma imagem for fornecida, prepare-a para a API de vis√£o
    if image:
        buffered = BytesIO()
        image.save(buffered, format="JPEG", quality=70) 
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        content_list.append({"type": "image_url", "image_url": {"url": f"data:image:jpeg;base64,{img_str}", "detail": "low"}})
        model_name = "gpt-4o" # Modelo multimodal mais recente da OpenAI
    else:
        model_name = "gpt-3.5-turbo" # Modelo de texto padr√£o

    messages_payload.append({"role": "user", "content": content_list})

    try:
        response = openai.chat.completions.create(
            model=model_name,
            messages=messages_payload,
            max_tokens=500, # Limite de tokens para a resposta do LLM
        )
        return response.choices[0].message.content
    except openai.APIError as e:
        st.error(f"Erro da API OpenAI: {e.status_code} - {e.response.json().get('error', {}).get('message', 'Mensagem de erro n√£o dispon√≠vel')}")
        st.exception(e) # Mostra o erro completo para debug
        return f"O Or√°culo encontrou um problema com a API OpenAI: {e.status_code}. Verifique sua chave e os limites de uso."
    except Exception as e:
        st.error(f"Ocorreu um erro inesperado com OpenAI: {e}")
        st.exception(e) # Mostra o erro completo para debug
        return "O Or√°culo n√£o conseguiu se comunicar com OpenAI. Tente novamente mais tarde."

def call_gemini_api(prompt: str, api_key: str, image: Image.Image = None) -> str:
    """
    Envia o prompt (e opcionalmente uma imagem) para a API Gemini e retorna a resposta.
    Utiliza modelos de vis√£o se uma imagem for fornecida.
    """
    if not api_key:
        return "Erro: Chave da API Gemini n√£o fornecida."

    try:
        genai.configure(api_key=api_key)
        
        if image:
            # Tenta usar o modelo de vis√£o armazenado na session_state.
            # Se n√£o existir ou for None, usa 'gemini-1.5-flash-latest' como fallback.
            model_name = st.session_state.get("gemini_vision_model", 'gemini-1.5-flash-latest')
            if model_name is None: # Verifica√ß√£o expl√≠cita se a valida√ß√£o falhou em encontrar um modelo
                return "Erro Gemini: Nenhum modelo de vis√£o compat√≠vel encontrado. Por favor, valide sua chave API na barra lateral."
            
            model = genai.GenerativeModel(model_name) 
            response = model.generate_content([prompt, image])
        else:
            # Tenta usar o modelo de texto armazenado na session_state.
            # Se n√£o existir ou for None, usa 'gemini-pro' como fallback.
            model_name = st.session_state.get("gemini_text_model", 'gemini-pro')
            if model_name is None: # Verifica√ß√£o expl√≠cita se a valida√ß√£o falhou em encontrar um modelo
                return "Erro Gemini: Nenhum modelo de texto compat√≠vel encontrado. Por favor, valide sua chave API na barra lateral."
            
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            
        return response.text
    except exceptions.NotFound as e: # Captura o erro espec√≠fico de modelo n√£o encontrado
        st.error(f"Erro: O modelo Gemini '{model_name}' n√£o foi encontrado. Por favor, valide sua chave API na barra lateral e verifique os modelos dispon√≠veis para sua regi√£o.")
        st.exception(e) # Mostra o erro completo para debug
        return "O Or√°culo n√£o conseguiu acessar o modelo Gemini. Verifique sua chave API e os modelos dispon√≠veis."
    except Exception as e:
        st.error(f"Ocorreu um erro inesperado com Gemini: {e}")
        st.exception(e) # Mostra o erro completo para debug
        return "O Or√°culo n√£o conseguiu se comunicar com Gemini. Tente novamente mais tarde. Verifique sua chave da API."

# --- Fun√ß√µes de Extra√ß√£o de Conte√∫do ---

def analyze_content(prompt: str, provider: str, api_key: str, image: Image.Image = None) -> str:
    """
    Realiza a an√°lise do conte√∫do (texto ou imagem) usando o provedor escolhido.
    Esta fun√ß√£o √© um dispatcher para as APIs de OpenAI e Gemini.
    """
    if provider == "OpenAI":
        return call_openai_api(prompt, api_key, image=image)
    return call_gemini_api(prompt, api_key, image=image)

def extract_images_from_pptx(file_bytes: BytesIO) -> list[Image.Image]:
    """Extrai e retorna todas as imagens de um arquivo PPTX."""
    pres = Presentation(file_bytes)
    images: list[Image.Image] = []
    for slide in pres.slides:
        for shape in slide.shapes:
            if hasattr(shape, "image"):
                try:
                    img_io = BytesIO(shape.image.blob)
                    img = Image.open(img_io)
                    # Converte para RGB para garantir compatibilidade com as APIs e evitar erros de modo
                    if img.mode in ("RGBA", "P"):
                        img = img.convert("RGB")
                    images.append(img)
                except UnidentifiedImageError:
                    st.warning(f"Um arquivo dentro do PPTX ({shape.name}) n√£o p√¥de ser identificado como imagem. Pulando.")
                except Exception as e:
                    st.warning(f"Erro ao extrair imagem ({shape.name}) do PPTX: {e}. Pulando.")
    return images

def extract_text_from_pdf(file_bytes: bytes) -> str:
    """Extrai texto de um PDF. Para an√°lise visual de PDF, considere PyMuPDF (fitz)."""
    try:
        reader = PyPDF2.PdfReader(BytesIO(file_bytes))
        text = ""
        for page in reader.pages:
            text += page.extract_text() or ""
        return text
    except PyPDF2.errors.PdfReadError:
        st.error("Erro ao ler o PDF. O arquivo pode estar corrompido ou protegido por senha.")
        return ""
    except Exception as e:
        st.error(f"Erro inesperado ao extrair texto do PDF: {e}")
        return ""

# --- Fun√ß√µes Auxiliares de UI ---
def display_example_images(sidebar_example_dir: Path):
    """Exibe imagens de exemplo na barra lateral, com tratamento de erros."""
    st.sidebar.markdown("---")
    st.sidebar.markdown("### Exemplos de Refer√™ncia")
    
    if not sidebar_example_dir.exists():
        st.sidebar.warning(f"A pasta de exemplos '{sidebar_example_dir.name}' n√£o foi encontrada.")
        st.sidebar.info(
            "Crie uma pasta chamada 'examples' na mesma pasta do seu script "
            "e adicione imagens JPEG ('.jpg' ou '.jpeg') l√°."
        )
    else:
        # Pega todos os arquivos .jpg e .jpeg
        image_paths = sorted(list(sidebar_example_dir.glob("*.jpg")) + list(sidebar_example_dir.glob("*.jpeg")))
        
        if not image_paths:
            st.sidebar.info("Nenhuma imagem JPEG (.jpg ou .jpeg) encontrada na pasta 'examples'.")
        else:
            num_columns = min(3, len(image_paths))  # Mostrar no m√°ximo 3 colunas
            columns = st.sidebar.columns(num_columns)
            
            for idx, image_path in enumerate(image_paths):
                try:
                    img_to_display = Image.open(image_path)
                    # Usa o m√≥dulo das colunas para exibir a imagem e a legenda
                    columns[idx % num_columns].image(img_to_display, caption=image_path.stem, use_column_width=True)
                except UnidentifiedImageError:
                    columns[idx % num_columns].error(
                        f"N√£o foi poss√≠vel exibir '{image_path.name}'. "
                        "O arquivo pode estar corrompido ou n√£o √© uma imagem v√°lida."
                    )
                except Exception as e:
                    columns[idx % num_columns].error(f"Erro inesperado ao carregar '{image_path.name}': {e}")


def validate_gemini_api_key(api_key: str):
    """Tenta configurar a API Gemini e lista os modelos dispon√≠veis."""
    if not api_key:
        st.sidebar.warning("Por favor, digite sua chave da API Gemini.")
        return
    
    try:
        genai.configure(api_key=api_key)
        
        list_models_response = genai.list_models()
        
        found_text_model = None
        found_vision_model = None
        
        st.sidebar.success("Chave da API Gemini validada com sucesso! Modelos dispon√≠veis:")
        
        model_names = []
        for m in list_models_response:
            model_names.append(m.name)
            if "generateContent" in m.supported_generation_methods:
                # Prioriza modelos mais recentes/multimodais para vis√£o
                # Adicionado 'gemini-1.5-pro' aqui, pois √© um modelo multimodal que pode ser usado com imagem
                if "gemini-1.5-flash" in m.name.lower() or "gemini-1.5-pro" in m.name.lower() or "vision" in m.name.lower():
                    if not found_vision_model:
                        found_vision_model = m.name
                # Prioriza gemini-pro para texto se n√£o for um modelo de vis√£o
                elif "gemini-pro" == m.name.lower(): 
                    if not found_text_model:
                        found_text_model = m.name
        
        st.sidebar.markdown(f"- **Texto:** `{found_text_model or 'Nenhum modelo de texto compat√≠vel encontrado.'}`")
        st.sidebar.markdown(f"- **Vis√£o:** `{found_vision_model or 'Nenhum modelo de vis√£o compat√≠vel encontrado.'}`")

        # Armazena na sess√£o para uso posterior, evitando re-listar modelos a cada re-run
        st.session_state["gemini_text_model"] = found_text_model
        st.session_state["gemini_vision_model"] = found_vision_model

        if not found_text_model and not found_vision_model:
            st.sidebar.error("Nenhum modelo Gemini compat√≠vel para 'generateContent' foi encontrado com esta chave de API. Verifique as permiss√µes do seu projeto no Google Cloud.")

    except exceptions.FailedPrecondition as e:
        st.sidebar.error(f"Falha na valida√ß√£o da API Gemini: {e.message}. Verifique se a API do Gemini est√° ativada no seu projeto Google Cloud.")
        st.exception(e)
    except exceptions.InvalidArgument as e:
        st.sidebar.error(f"Falha na valida√ß√£o da API Gemini: {e.message}. A chave da API √© inv√°lida.")
        st.exception(e)
    except Exception as e:
        st.sidebar.error(f"Ocorreu um erro inesperado ao validar a API Gemini: {e}")
        st.exception(e)


# --- Interface Principal do Streamlit ---

def main() -> None:
    """Interface principal em Streamlit."""

    st.title("Or√°culo de Fachadas Brahma üç∫")
    st.markdown(
        "<p style='font-size:1.1em; text-align:center;'> "
        "Envie imagens, PDFs ou apresenta√ß√µes PPTX para obter um diagn√≥stico inicial "
        "sobre fachadas Brahma. Informe sua chave da API na barra lateral para prosseguir."
        "</p>", unsafe_allow_html=True
    )
    st.markdown("---")

    # --- Sidebar (Configura√ß√µes e Upload de Arquivos) ---
    with st.sidebar:
        st.header("Configura√ß√µes do Or√°culo")
        provider = st.selectbox("Escolha o Provedor da IA", ["OpenAI", "Gemini"], key="provider_select")
        api_key = st.text_input(f"Sua Chave de API ({provider})", type="password", key="api_key_input")

        if st.button("Validar API Key", key="validate_api_btn"):
            if provider == "OpenAI":
                if api_key:
                    openai.api_key = api_key
                    try:
                        # Tenta listar modelos para validar a chave OpenAI
                        openai.models.list() 
                        st.sidebar.success("Chave da API OpenAI validada com sucesso!")
                    except openai.APIError as e:
                        st.sidebar.error(f"Erro na API OpenAI: {e.status_code}. Verifique sua chave.")
                        st.exception(e)
                    except Exception as e:
                        st.sidebar.error(f"Erro inesperado ao validar OpenAI: {e}")
                        st.exception(e)
                else:
                    st.sidebar.warning("Por favor, digite sua chave da API OpenAI.")
            elif provider == "Gemini":
                validate_gemini_api_key(api_key)

        st.markdown("---")
        st.subheader("Envie seu Arquivo")
        uploaded_file = st.file_uploader(
            "Selecione uma imagem, PDF ou PPTX para an√°lise:",
            type=["png", "jpg", "jpeg", "pdf", "pptx"],
            key="sidebar_file_uploader"
        )
        st.info(
            "Ap√≥s enviar o arquivo, clique 'Enviar para An√°lise' no campo de chat "
            "para process√°-lo e obter a resposta do Or√°culo."
        )

        display_example_images(Path("examples"))

    # --- Hist√≥rico do Chat ---
    # Usando uma div HTML com altura fixa e overflow para o hist√≥rico de chat
    st.markdown("<div id='chat-history' style='height: 400px; overflow-y: auto; padding: 10px; border: 1px solid #ddd; border-radius: 8px;'>", unsafe_allow_html=True)
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Exibir Mensagens Anteriores
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            # Exibe imagem se existir
            if "image" in message and message["image"] is not None:
                if isinstance(message["image"], Image.Image):
                    st.image(message["image"], caption="Imagem enviada", width=200)
                elif isinstance(message["image"], (str, Path)): # Para exibir caminhos de arquivo (ex: imagens de exemplo)
                    st.image(str(message["image"]), caption="Imagem de Exemplo", width=200)
            
            # Exibe texto
            if "text" in message:
                st.markdown(message["text"])
            
            # Exibe preview de texto extra√≠do se existir
            if "extracted_text_preview" in message and message["extracted_text_preview"]:
                with st.expander("Ver texto extra√≠do do documento"):
                    st.text_area("Conte√∫do extra√≠do", message["extracted_text_preview"], height=150, disabled=True)
    
    st.markdown("</div>", unsafe_allow_html=True) # Fecha a div do hist√≥rico
    
    # --- Campo de Entrada do Chat (abaixo do hist√≥rico) ---
    # user_input_text √© definido dentro do st.form e tem seu valor no submit
    # Aqui, garantimos que ele n√£o ser√° None se o formul√°rio n√£o foi submetido ainda
    user_input_text_form = "" # Vari√°vel auxiliar para o st.text_area

    with st.form("chat_form", clear_on_submit=True):
        user_input_text_form = st.text_area("O que voc√™ gostaria de perguntar ao Or√°culo?", 
                                        height=80, 
                                        placeholder="Por exemplo: 'Analise esta fachada e me diga se ela segue o padr√£o Brahma.'",
                                        key="user_text_input") # Adicionado key para consist√™ncia
        
        submit_button = st.form_submit_button("Enviar para An√°lise")

    # A l√≥gica de processamento deve ser acionada SOMENTE SE o bot√£o foi clicado
    if submit_button:
        # Usamos user_input_text_form aqui, pois ele cont√©m o valor do text_area no momento do submit
        user_input_text = user_input_text_form

        # uploaded_file √© definido na sidebar, ent√£o est√° dispon√≠vel aqui
        
        # Se um arquivo foi enviado na sidebar, mas nenhum texto foi digitado,
        # define um texto padr√£o para o prompt.
        if uploaded_file and not user_input_text:
            user_input_text = f"Analisar o arquivo: {uploaded_file.name}. Por favor, me d√™ um diagn√≥stico."

        if not api_key:
            st.error("Por favor, **informe a API Key** na barra lateral para iniciar a an√°lise.")
            return # Sai da fun√ß√£o main

        if not user_input_text and not uploaded_file:
            st.warning("Por favor, digite uma pergunta ou envie um arquivo para analisar.")
            return # Sai da fun√ß√£o main

        # --- L√≥gica de Processamento da Mensagem do Usu√°rio ---
        user_message_content = {"role": "user", "text": user_input_text}
        
        # Vari√°vel para a imagem que ser√° enviada para a API (se houver)
        image_for_api_analysis = None 

        if uploaded_file:
            file_name = uploaded_file.name.lower()
            user_message_content["display_text"] = f"Voc√™ enviou o arquivo: `{file_name}`"
            
            if file_name.endswith((".png", ".jpg", ".jpeg")):
                try:
                    img = Image.open(uploaded_file)
                    user_message_content["image"] = img # Guarda a imagem PIL para exibir no chat
                    image_for_api_analysis = img # Define a imagem para ser analisada pela API
                except UnidentifiedImageError:
                    st.error("Erro: N√£o foi poss√≠vel identificar a imagem enviada. Verifique se o arquivo est√° correto.")
                    return
                except Exception as e:
                    st.error(f"Erro ao carregar a imagem: {e}")
                    return
            elif file_name.endswith(".pptx"):
                user_message_content["file_type"] = "pptx"
                user_message_content["file_content"] = uploaded_file # Passa o BytesIO
            elif file_name.endswith(".pdf"):
                user_message_content["file_type"] = "pdf"
                user_message_content["file_content"] = uploaded_file.read() # Passa os bytes do PDF
            else:
                st.warning("Tipo de arquivo n√£o suportado para an√°lise direta. Por favor, use texto, imagem, PDF ou PPTX.")
                return

        # Adicionar a mensagem do usu√°rio ao hist√≥rico antes de chamar a API
        st.session_state.messages.append(user_message_content)

        # Exibir a mensagem do usu√°rio imediatamente
        with st.chat_message("user"):
            if "image" in user_message_content and user_message_content["image"] is not None:
                st.image(user_message_content["image"], caption="Imagem enviada", width=200)
            st.markdown(user_message_content.get("display_text", user_input_text))


        # --- Chamar a API e obter a resposta do Or√°culo ---
        with st.chat_message("assistant"):
            with st.spinner("O Or√°culo est√° consultando os ventos da an√°lise..."):
                response_text = "Desculpe, o Or√°culo est√° com problemas. Tente novamente mais tarde."
                extracted_text_for_chat = "" # Para armazenar texto extra√≠do de PDF/PPTX para o hist√≥rico

                if image_for_api_analysis: # Se uma imagem foi carregada diretamente
                    # A IA analisa a imagem com o prompt inicial do usu√°rio
                    response_text = analyze_content(user_input_text, provider, api_key, image=image_for_api_analysis)
                elif "file_type" in user_message_content and user_message_content["file_type"] == "pptx":
                    st.markdown("Extraindo imagens da apresenta√ß√£o...")
                    images_from_pptx = extract_images_from_pptx(user_message_content["file_content"])
                    if images_from_pptx:
                        full_analysis_output = []
                        for idx, img in enumerate(images_from_pptx):
                            st.image(img, caption=f"Imagem do Slide {idx + 1}", width=200)
                            # Analisa cada imagem do PPTX com um prompt espec√≠fico para imagem
                            analysis_result = analyze_content(f"Analise a imagem {idx+1} da fachada:", provider, api_key, image=img)
                            full_analysis_output.append(f"**An√°lise da Imagem {idx + 1}:**\n{analysis_result}")
                        response_text = "\n\n".join(full_analysis_output)
                        if not full_analysis_output:
                             response_text = "Nenhuma imagem v√°lida p√¥de ser extra√≠da do PPTX para an√°lise."
                    else:
                        response_text = "N√£o consegui extrair imagens desta apresenta√ß√£o PPTX para an√°lise."
                elif "file_type" in user_message_content and user_message_content["file_type"] == "pdf":
                    st.markdown("Extraindo texto do PDF...")
                    text_from_pdf = extract_text_from_pdf(user_message_content["file_content"])
                    extracted_text_for_chat = text_from_pdf # Guarda para exibir no hist√≥rico
                    if text_from_pdf:
                        st.text_area("Texto extra√≠do (para refer√™ncia)", text_from_pdf, height=100, disabled=True)
                        # Analisa o texto extra√≠do do PDF com o prompt do usu√°rio
                        response_text = analyze_content(f"Analise o texto: {text_from_pdf}", provider, api_key)
                    else:
                        response_text = "N√£o consegui extrair texto deste PDF para an√°lise."
                elif user_input_text: # An√°lise de texto puro
                    response_text = analyze_content(user_input_text, provider, api_key)
                
            st.markdown(response_text)
            # Adicionar a resposta do assistente ao hist√≥rico
            assistant_message_content = {"role": "assistant", "text": response_text}
            if extracted_text_for_chat:
                assistant_message_content["extracted_text_preview"] = extracted_text_for_chat
            st.session_state.messages.append(assistant_message_content)

# --- Execu√ß√£o do Aplicativo ---
if __name__ == "__main__":
    main()